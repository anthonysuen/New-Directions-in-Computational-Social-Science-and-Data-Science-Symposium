<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet2.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
<title>New Directions In Computational Social Science &amp; Data Science </title>
  </head>
  <body>
    <header>
      <div class="inner">
        <h3>Symposium on<h3>
        <h2>New Directions in Computational Social Science &amp; Data Science </h2>
        <h4>April 25 9 - 5pm  April 26 9 - 12pm </h4>
        <h4>Simons Institute for the Theory of Computing</h4> 
        <h4>University of California, Berkeley</h4>
        <a href="http://www.tfaforms.com/419098/" class="button">Register Now</a>
    </header>
    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h4>Privacy for the Protected (Only)</h4>
          <h4>Michael Kearns</h4>
          <p>Motivated by tensions between data privacy for individual citizens
and societal priorities such as counterterrorism and the containment
of infectious disease, we introduce a computational model
that distinguishes between parties for whom privacy is explicitly
protected, and those for whom it is not (the targeted subpopulation).
The goal is the development of algorithms that can effectively
identify and take action upon members of the targeted subpopulation
in a way that minimally compromises the privacy of the
protected, while simultaneously limiting the expense of distinguishing
members of the two groups via costly mechanisms such as
surveillance, background checks, or medical testing. Within this
framework, we provide provably privacy-preserving algorithms for
targeted search in social networks. These algorithms are natural
variants of common graph search methods, and ensure privacy for
the protected by the careful injection of noise in the prioritization
of potential targets. We validate the utility of our algorithms
with extensive computational experiments on two large-scale social
network datasets.  [Joint research with Aaron Roth, Zhiwei Steven Wu,
and Grigory Yaroslavtsev.]</p>
</html>



